# data_enricher.py
"""
[ë°ì´í„° ë³´ê°• í†µí•© ëª¨ë“ˆ]
ìˆ˜ì§‘ëœ ì œí’ˆ ë°ì´í„°ì˜ íƒœê·¸ì™€ ì„±ë¶„ ì •ë³´ë¥¼ ë³´ê°•í•©ë‹ˆë‹¤.
1ë‹¨ê³„: Regex(ì •ê·œí‘œí˜„ì‹)ë¡œ ë¹ ë¥´ê³  ë¬´ë£Œë¡œ ë¶„ì„ (ë¡œì»¬)
2ë‹¨ê³„: ì •ë³´ê°€ ë¶€ì¡±í•œ ì œí’ˆë§Œ ê³¨ë¼ì„œ GPTì—ê²Œ ë¶„ì„ ìš”ì²­ (API)
"""

import re
import json
import time
import logging
import psycopg2
from dotenv import load_dotenv

from .config import DB_CONFIG, STANDARD_TAGS, STANDARD_INGREDIENTS
from .gpt_api import analyze_batch_product_tags

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

# [ìµœì í™”] ë°°ì¹˜ ì‚¬ì´ì¦ˆ 50ìœ¼ë¡œ ì¦ê°€ (ì†ë„ í–¥ìƒ)
BATCH_SIZE = 50

# ==============================================================================
# [PART 1] Regex íŒ¨í„´ ì •ì˜ (ë‹¨ì–´ì¥)
# ==============================================================================
# config.pyì˜ STANDARD_TAGS, STANDARD_INGREDIENTSì— ì •ì˜ëœ í‚¤ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.
PATTERNS = {
    "ingredients": {
        "teatree": r"í‹°íŠ¸ë¦¬|tea\s?tree",
        "cica": r"ì‹œì¹´|ë³‘í’€|ì„¼í…”ë¼|ë§ˆë°ì¹´|cica|centella",
        "heartleaf": r"ì–´ì„±ì´ˆ|ì•½ëª¨ë°€|heartleaf",
        "mugwort": r"ì‘¥|ì‚¬ì² ì‘¥|ì¸ì§„ì‘¥|mugwort|artemisia",
        "hyaluronic": r"íˆì•Œë£¨ë¡ |í•˜ì´ë“œë¼|ìˆ˜ë¶„|hyaluronic",
        "ceramide": r"ì„¸ë¼ë§ˆì´ë“œ|ì„¸ë¼|ceramide",
        "panthenol": r"íŒí…Œë†€|panthenol",
        "propolis": r"í”„ë¡œí´ë¦¬ìŠ¤|ê¿€|ë¡œì–„ì ¤ë¦¬|propolis",
        "vitamin-c": r"ë¹„íƒ€ë¯¼|ë¹„íƒ€ë¯¼C|ì¡í‹°|ì²­ê·¤|ìœ ì|vita",
        "niacinamide": r"ë‚˜ì´ì•„ì‹ |ë¯¸ë°±|niacin",
        "retinol": r"ë ˆí‹°ë†€|ë ˆí‹°ë‚ |retinol|retinal",
        "collagen": r"ì½œë¼ê²|íƒ„ë ¥|collagen",
        "bha": r"ë°”í•˜|ì‚´ë¦¬ì‹¤ì‚°|bha|salicylic",
        "aha": r"ì•„í•˜|ê¸€ë¼ì´ì½œë¦­|aha|glycolic",
        "shea-butter": r"ì‰ì–´ë²„í„°|shea\s?butter",
        "azelaic": r"ì•„ì ¤ë¼ìµ|azelaic",
        "pha": r"íŒŒí•˜|pha"
    },
    "tags": {
        "soothing": r"ì§„ì •|ìˆ˜ë”©|ì¿¨ë§|ì‹œì¹´|í‹°íŠ¸ë¦¬|ì–´ì„±ì´ˆ",
        "moisturizing": r"ë³´ìŠµ|ìˆ˜ë¶„|ë¬¼ê´‘|ì´‰ì´‰|íˆì•Œë£¨ë¡ ",
        "barrier": r"ì¥ë²½|íŒí…Œë†€|ì„¸ë¼ë§ˆì´ë“œ|ì¬ìƒ",
        "brightening": r"ë¯¸ë°±|í†¤ì—…|ë¸Œë¼ì´íŠ¸ë‹|ì¡í‹°|ë¹„íƒ€ë¯¼|í™”ì´íŠ¸ë‹",
        "anti-aging": r"ì£¼ë¦„|íƒ„ë ¥|ì•ˆí‹°ì—ì´ì§•|ë¦¬í”„íŒ…|ë…¸í™”|ë ˆí‹°ë†€",
        "acne-care": r"íŠ¸ëŸ¬ë¸”|ì—¬ë“œë¦„|ì•„í¬ë„¤|ì§„ì •|í‹°íŠ¸ë¦¬",
        "pore-care": r"ëª¨ê³µ|í”¼ì§€|ë¸”ë™í—¤ë“œ",
        "sebum-care": r"í”¼ì§€|ê°œê¸°ë¦„|ì‚°ëœ»",
        "spf": r"ì„ í¬ë¦¼|ì„ ë¸”ë¡|ì„ ìŠ¤í‹±|ìì°¨|spf|pa\+",
        "hydration": r"ìˆ˜ë¶„|hydration",
        "firming": r"íƒ„ë ¥|firming",
        "sensitive-skin": r"ë¯¼ê°|ì €ìê·¹|ìˆœí•œ|ì•½ì‚°ì„±",
        "oily-skin": r"ì§€ì„±|í”¼ì§€|ê°œê¸°ë¦„|ì‚°ëœ»|ê°€ë²¼ìš´",
        "dry-skin": r"ê±´ì„±|ì†ê±´ì¡°|ë‹¹ê¹€",
        "vegan": r"ë¹„ê±´|vegan",
        "low-ph": r"ì•½ì‚°ì„±|low\s?ph",
        "hypoallergenic": r"ì €ìê·¹|hypoallergenic",
        "fragrance-free": r"ë¬´í–¥|fragrance\s?free",
        "alcohol-free": r"ë¬´ì•Œì½œ|alcohol\s?free",
        "light": r"ê°€ë²¼ìš´|ì‚°ëœ»|light",
        "rich": r"ì˜ì–‘|rich|ê¾¸ë•",
        "gel": r"ì ¤|gel",
        "cream": r"í¬ë¦¼|cream",
        "watery": r"ì›Œí„°|watery|ë¬¼",
        "oil": r"ì˜¤ì¼|oil",
        "balm": r"ë°¤|balm",
        "fresh": r"ìƒì¾Œ|fresh"
    }
}


def analyze_text_local(text):
    """Regex ì—”ì§„: í…ìŠ¤íŠ¸ì—ì„œ ì„±ë¶„ê³¼ íƒœê·¸ ì¶”ì¶œ"""
    found_ings = set()
    found_tags = set()
    text_lower = text.lower()

    for ing_name, pattern in PATTERNS["ingredients"].items():
        if ing_name in STANDARD_INGREDIENTS and re.search(pattern, text_lower):
            found_ings.add(ing_name)

    for tag_name, pattern in PATTERNS["tags"].items():
        if tag_name in STANDARD_TAGS and re.search(pattern, text_lower):
            found_tags.add(tag_name)

    return list(found_ings), list(found_tags)


# ==============================================================================
# [PART 2] 1ë‹¨ê³„: Regex ì¼ê´„ ì²˜ë¦¬
# ==============================================================================
def enrich_with_regex():
    logger.info("ğŸ”¹ [Phase 1] Regex ì—”ì§„ ê°€ë™ (Local Processing)...")
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        cursor.execute("SELECT id, name, official_category FROM products")
        products = cursor.fetchall()

        updates = []
        count = 0

        for p in products:
            p_id, name, cat = p

            ings, tags = analyze_text_local(name)
            if cat == "Sunscreen": tags.append("spf50")

            ings = list(set(ings))
            tags = list(set(tags))

            if ings or tags:
                updates.append((json.dumps(tags), json.dumps(ings), p_id))
                count += 1

        if updates:
            sql = "UPDATE products SET tags = %s, featured_ingredients = %s WHERE id = %s"
            cursor.executemany(sql, updates)
            conn.commit()

        logger.info(f"âœ… Regex ì™„ë£Œ: {count}ê°œ ì œí’ˆ ì •ë³´ 1ì°¨ ë³´ê°•ë¨.")
        cursor.close()
        conn.close()
    except Exception as e:
        logger.error(f"Regex ë‹¨ê³„ ì‹¤íŒ¨: {e}")


# ==============================================================================
# [PART 3] 2ë‹¨ê³„: GPT ì—”ì§„ (gpt_api ëª¨ë“ˆ ì‚¬ìš©)
# ==============================================================================

def get_poor_data_products():
    """íƒœê·¸ê°€ ë¶€ì¡±í•œ ì œí’ˆ ì¡°íšŒ (ì¹´í…Œê³ ë¦¬ë³„ ì •ë ¬)"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        query = """
            SELECT id, name, official_category, tags, featured_ingredients 
            FROM products 
            ORDER BY official_category, id
        """
        cursor.execute(query)
        rows = cursor.fetchall()

        targets = []
        for r in rows:
            tags = json.loads(r[3]) if r[3] else []
            if len(tags) < 2:
                targets.append(r)  # ì „ì²´ rowë¥¼ ë‹¤ ë„£ìŒ

        cursor.close()
        conn.close()
        return targets
    except Exception as e:
        logger.error(f"Target ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def enrich_with_gpt():
    logger.info("ğŸ”¹ [Phase 2] GPT ì—”ì§„ ê°€ë™ (AI Processing)...")

    targets = get_poor_data_products()
    total = len(targets)
    logger.info(f"ğŸ“‹ GPT ë³´ê°• ëŒ€ìƒ: {total}ê°œ")

    if total == 0: return

    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()

    # ë°°ì¹˜ ì²˜ë¦¬ (50ê°œì”©)
    for i in range(0, total, BATCH_SIZE):
        batch = targets[i: i + BATCH_SIZE]
        logger.info(f"   ğŸ”„ Batch {i // BATCH_SIZE + 1} Processing ({len(batch)} items)...")

        # [ìˆ˜ì •] ì§ì ‘ í˜¸ì¶œ ëŒ€ì‹  gpt_api ëª¨ë“ˆì˜ í•¨ìˆ˜ ì‚¬ìš©!
        # batchëŠ” (id, name, cat, ...) íŠœí”Œì´ë¯€ë¡œ ì•ì˜ 3ê°œë§Œ ì˜ë¼ì„œ ë³´ëƒ„
        batch_input = [(p[0], p[1], p[2]) for p in batch]
        gpt_res = analyze_batch_product_tags(batch_input)

        updates = []
        for p in batch:
            p_id = str(p[0])
            if p_id in gpt_res:
                data = gpt_res[p_id]

                old_tags = json.loads(p[3]) if p[3] else []
                old_ings = json.loads(p[4]) if p[4] else []

                new_tags = list(set(old_tags + data.get("tags", [])))
                new_ings = list(set(old_ings + data.get("ingredients", [])))

                # ì—…ë°ì´íŠ¸ ì¿¼ë¦¬ ì¤€ë¹„
                updates.append((json.dumps(new_tags), json.dumps(new_ings), p[0]))

        # DB ì €ì¥
        if updates:
            cursor.executemany(
                "UPDATE products SET tags=%s, featured_ingredients=%s WHERE id=%s",
                updates
            )
            conn.commit()

        time.sleep(0.5)

    cursor.close()
    conn.close()
    logger.info("âœ… GPT ë³´ê°• ì™„ë£Œ!")


# ==============================================================================
# [MAIN] ì‹¤í–‰ ì»¨íŠ¸ë¡¤ëŸ¬
# ==============================================================================
def run_hybrid_enrichment():
    enrich_with_regex()  # 1ì°¨
    enrich_with_gpt()  # 2ì°¨
    logger.info("ğŸ‰ [ë°ì´í„° ìµœì í™” ì™„ë£Œ] ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")


if __name__ == "__main__":
    run_hybrid_enrichment()
