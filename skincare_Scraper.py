# skincare_Scraper.py
"""
[ì˜¬ë¦¬ë¸Œì˜ ëž­í‚¹ ë°ì´í„° ìˆ˜ì§‘ ë° ê°€ê³µ ë‹´ë‹¹]
ì´ íŒŒì¼ì€ ì˜¬ë¦¬ë¸Œì˜ ì›¹ì‚¬ì´íŠ¸ì˜ ëž­í‚¹ íŽ˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ìƒí’ˆ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

1. í™˜ê²½ ì„¤ì • ë¡œë“œ ë° Selenium ì›¹ ë“œë¼ì´ë²„ ì‹¤í–‰ (config.py, utils.py í™œìš©)
2. ì˜¬ë¦¬ë¸Œì˜ ëž­í‚¹ íŽ˜ì´ì§€ ì ‘ì† í›„ íŒì—… ë‹«ê¸° ë° ìŠ¤í¬ë¡¤ ë‹¤ìš´(ë™ì  ë¡œë”© ì²˜ë¦¬)
3. BeautifulSoupì„ í™œìš©í•´ HTML êµ¬ì¡° íŒŒì‹± ë° ìƒí’ˆë³„ ë°ì´í„° ì¶”ì¶œ
4. ì¶”ì¶œëœ ì •ë³´(ìƒí’ˆëª…, ê°€ê²©, í• ì¸ìœ¨ ë“±)ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ CSV ì €ìž¥
"""

import time
import random
import pandas as pd
from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By

# [ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° ë¶ˆëŸ¬ì˜¤ê¸°]
# config.py: URL, ì €ìž¥ íŒŒì¼ëª… ë“± ë³€ê²½ë  ìˆ˜ ìžˆëŠ” ì„¤ì •ê°’
# utils.py: ë¸Œë¼ìš°ì € ì‹¤í–‰, ê°€ê²© ìˆ«ìž ë³€í™˜, ìŠ¤í¬ë¡¤ ë“± ë°˜ë³µë˜ëŠ” ê¸°ëŠ¥ í•¨ìˆ˜
from config import OLIVEYOUNG_URL, SCRAPED_DATA_PATH
from utils import setup_chrome_driver, clean_price_text, scroll_to_bottom


def main():
    # 1. ë¸Œë¼ìš°ì € ë“œë¼ì´ë²„ ì„¤ì • ë° ì‹¤í–‰
    # (OSë¥¼ ê°ì§€í•˜ì—¬ ì ì ˆí•œ ì˜µì…˜ìœ¼ë¡œ í¬ë¡¬ì„ ì¼­ë‹ˆë‹¤ - utils.py ì°¸ì¡°)
    driver = setup_chrome_driver()
    if not driver:
        return

    try:
        # 2. ì˜¬ë¦¬ë¸Œì˜ ëž­í‚¹ íŽ˜ì´ì§€ ì ‘ì†
        print(f"ðŸŒ ì ‘ì† ì¤‘: {OLIVEYOUNG_URL}")
        driver.get(OLIVEYOUNG_URL)

        # [ì¤‘ìš”] ì‚¬ì´íŠ¸ ë³´ì•ˆ(Cloudflare) ë° ë¡œë”©ì„ ìœ„í•´ ëžœë¤ ì‹œê°„ ëŒ€ê¸°
        time.sleep(random.uniform(5, 8))

        # 3. íŒì—…ì°½ ë‹«ê¸° (íŒì—…ì´ ë–´ì„ ê²½ìš°ì—ë§Œ ì²˜ë¦¬)
        try:
            close_btn = driver.find_element(By.CLASS_NAME, 'pop_close_btn')
            close_btn.click()
            print("âœ… íŒì—… ë‹«ê¸° ì™„ë£Œ")
            time.sleep(1)
        except:
            # íŒì—…ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
            pass

        # 4. íŽ˜ì´ì§€ ìŠ¤í¬ë¡¤ (ë” ë§Žì€ ìƒí’ˆ ë¡œë”©)
        # utils.pyì— ìžˆëŠ” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ í™”ë©´ì„ 5ë²ˆ ë‚´ë¦½ë‹ˆë‹¤.
        scroll_to_bottom(driver, count=5)

        # [ìˆ˜ì •ëœ ì½”ë“œ ì‹œìž‘] ==========================================
        # 5. HTML íŒŒì‹± (BeautifulSoup)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        data_list = []

        # ðŸ’¡ ê¸°ì¡´ ë°©ì‹(ul í´ëž˜ìŠ¤ ì°¾ê¸°) ëŒ€ì‹ , ìƒí’ˆ ì´ë¦„(.tx_name)ì´ ìžˆëŠ” ê³³ì„ ë¨¼ì € ì°¾ìŠµë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•˜ë©´ ìƒìœ„ íƒœê·¸(ul) ì´ë¦„ì´ ë°”ë€Œì–´ë„ ë¬¸ì œì—†ì´ ì°¾ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
        name_tags = soup.select('.tx_name')

        print(f"ðŸ“¦ ë°œê²¬ëœ ìƒí’ˆ ì´ë¦„ íƒœê·¸: {len(name_tags)}ê°œ")

        # ìƒí’ˆ ì´ë¦„ íƒœê·¸ë¥¼ í•˜ë‚˜ì”© ëŒë©´ì„œ ì „ì²´ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        for name_tag in name_tags:
            try:
                # 1. ìƒí’ˆ ì»¨í…Œì´ë„ˆ(li) ì°¾ê¸°: ì´ë¦„ íƒœê·¸ì˜ ë¶€ëª¨(li)ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                container = name_tag.find_parent('li')
                if not container: continue

                # 2. ìƒí’ˆëª… ì¶”ì¶œ
                name = name_tag.text.strip()

                # 3. ê°€ê²© ì¶”ì¶œ
                final_tag = container.select_one('.tx_cur')  # í• ì¸ê°€(ìµœì¢…ê°€)
                org_tag = container.select_one('.tx_org')  # ì •ê°€(ì›ê°€)

                final_price = clean_price_text(final_tag.text) if final_tag else 0
                # ì •ê°€ê°€ ì—†ìœ¼ë©´ í• ì¸ê°€ë¥¼ ì •ê°€ë¡œ ì·¨ê¸‰
                org_price = clean_price_text(org_tag.text) if org_tag else final_price

                # 4. í• ì¸ìœ¨ ê³„ì‚°
                discount = 0.0
                if org_price > 0 and final_price < org_price:
                    discount = round(((org_price - final_price) / org_price) * 100, 1)

                # 5. ìƒí’ˆ ID ë° ë§í¬ ì¶”ì¶œ
                link_tag = container.select_one('a')
                pid = "N/A"
                link = ""

                if link_tag:
                    link = link_tag.get('href', "")
                    # data-ref-goodsno ì†ì„±ì´ ìžˆìœ¼ë©´ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ URLì—ì„œ ì¶”ì¶œ ì‹œë„
                    if link_tag.has_attr('data-ref-goodsno'):
                        pid = link_tag['data-ref-goodsno']

                # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                data_list.append({
                    'ID': pid,
                    'ìƒí’ˆëª…': name,
                    'ì›ê°€': org_price,
                    'ìµœì¢…ê°€': final_price,
                    'í• ì¸ìœ¨': discount,
                    'URL': link
                })

            except Exception as e:
                print(f"âš ï¸ ìƒí’ˆ íŒŒì‹± ì¤‘ ì—ëŸ¬: {e}")
                continue

        # 7. ë°ì´í„° ì €ìž¥ (CSV)
        if data_list:
            df = pd.DataFrame(data_list)
            # utf-8-sig: ì—‘ì…€ì—ì„œ í•œê¸€ ê¹¨ì§ ë°©ì§€
            df.to_csv(SCRAPED_DATA_PATH, index=False, encoding='utf-8-sig')
            print(f"ðŸ’¾ ì €ìž¥ ì™„ë£Œ: {SCRAPED_DATA_PATH} ({len(df)}ê°œ)")
        else:
            print("âš ï¸ ì €ìž¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âš ï¸ ì „ì²´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    finally:
        # [í•„ìˆ˜] ì—ëŸ¬ ë°œìƒ ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ ë¸Œë¼ìš°ì €ëŠ” ë°˜ë“œì‹œ ì¢…ë£Œ
        driver.quit()
        print("ðŸ‘‹ ì¢…ë£Œ")


if __name__ == "__main__":
    main()